{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut Implimentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our goal is to create marker predict using Deeplabcut. The output of this code will be the Marker predictions file(.csv file) and a video with the marker predictions on the animal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mount your google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the marker predictions, we need the config file created in the previous step. The directories below should be modified to include the locations of these files on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change your current directory so you are in the folder where you config file is located \n",
    "%cd /content/drive/My Drive/trial3-team12-2019-09-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install deeplabcut so that you can use the build in functions created by DeepLabCut to obtain the marker predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install deeplabcut \n",
    "!pip install deeplabcut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install an tensorflow versoun 1.13 becuase DeepLabCut only runs on an older version of tensor flow. If you do not do this step, DeepLabCut will not run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install tensor flow - you need to do this step becuase DeepLabCut runs on an older version of tensor flow \n",
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import all your librabries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import os\n",
    "os.environ[\"DLClight\"]=\"True\"\n",
    "os.environ[\"Colab\"]=\"True\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import deeplabcut\n",
    "import pandas as pd\n",
    "from pandas_datareader import data, wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directories below should be modified to include the locations of the config file on your google drive. This step sets the variable you are going to pass in when you train the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change your path file to the correct directory \n",
    "path_config_file = '/content/drive/My Drive/trial4/2ratsIR_trial-team12-2019-10-11/config_google.yaml' #this just sets the variable that your gonna pass in when ur gonna train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step allows you to create the training dataset. Set the config file below to the video you would like to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training dataset\n",
    "deeplabcut.create_training_dataset(path_config_file,num_shuffles=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train the network. It is recommended to train for thousands of iterations until the loss plateaus (typically >200,000). The variables ‘display_iters’ and ‘save_iters’ in the pose_cfg.yaml file allows the user to alter how often the loss is displayed and how often the weights are stored.The function ‘train_network’ helps the user in training the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the network\n",
    "deeplabcut.train_network(path_config_file,maxiters=10000,displayiters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to evaluate the performance of the trained network. This performance is measured by computing the mean average Euclidean error (MAE; which is proportional to the average root mean square error) between the manual labels and the ones predicted by DeepLabCut. The MAE is saved as a comma separated file and displayed for all pairs and only likely pairs (>p-cutoff). This helps to exclude, for example, occluded body parts. One of the strengths of DeepLabCut is that due to the probabilistic output of the scoremap, it can, if sufficiently trained, also reliably report if a body part is visible in a given frame. Setting ‘plotting’ to true plots all the testing and training frames with the manual and predicted labels. The user should visually check the labeled test (and training) images that are created in the ‘evaluation-results’ directory. Ideally, DeepLabCut labeled unseen (test images) according to the user’s required accuracy, and the average train and test errors are comparable (good generalization). What (numerically) comprises an acceptable MAE depends on many factors (including the size of the tracked body parts, the labeling variability, etc.). Note that the test error can also be larger than the training error due to human variability. The plots can be customized by editing the config.yaml file (i.e. the colormap, scale, marker size (dotsize), and transparency of labels (alphavalue) can be modified). By default each body part is plotted in a different color (governed by the colormap) and the plot labels indicate their source. Note that by default the human labels are plotted as plus (‘+’), DeepLabCut’s predictions either as ‘.’ (for confident predictions with likelihood > p-cutoff) and ’x’ for (likelihood <= p-cutoff). The evaluation results for each shuffle of the training dataset are stored in a unique subdirectory in a newly created directory ‘evaluation-results’ in the project directory. The user can visually inspect if the distance between the labeled and the predicted body parts is acceptable. In the event of benchmarking with different shuffles of same training dataset, the user can provide multiple shuffle indices to evaluate the corresponding network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalulate the network \n",
    "deeplabcut.evaluate_network(path_config_file,plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained network can be used to analyze new videos. The user needs to first choose a checkpoint with the best evaluation results for analyzing the videos. In this case, the user can enter the corresponding index of the checkpoint to the variable snapshotindex in the config.yaml file. By default, the most recent checkpoint (i.e. last) is used for analyzing the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze the video \n",
    "deeplabcut.analyze_videos(path_config_file,['/content/drive/My Drive/trial4/2ratsIR_trial-team12-2019-10-11/videos/2ratsIRbag.avi'],save_as_csv=True,videotype='.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are stored in a MultiIndex Pandas Array ( http://pandas.pydata.org), which contains the name of the network, body part name, (x, y) label position in pixels, and the likelihood for each frame per body part. These arrays are stored in an efficient Hierarchical Data Format (HDF) in the same directory, where the video is stored. However, if the flag save_as_csv is set to True, the data can also be exported in comma-separated values format (.csv), which in turn can be imported in many programs, such as MATLAB, R, Prism, etc.; This flag is set to False by default. The labels for each body part across the video (‘trajectories’) can also be plotted after analyze_videos is run. The provided plotting function in this toolbox utilizes matplotlib therefore these plots can easily be customized by the end user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create labeled video \n",
    "deeplabcut.create_labeled_video(path_config_file,['/content/drive/My Drive/trial4/2ratsIR_trial-team12-2019-10-11/videos/2ratsIRbag.avi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot trajectories \n",
    "deeplabcut.plot_trajectories(config_path,['/content/drive/My Drive/trial4/2ratsIR_trial-team12-2019-10-11/videos/2ratsIRbag.avi'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
